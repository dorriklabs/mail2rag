from __future__ import annotations

import base64
import logging
from pathlib import Path
from typing import Any, Dict, Optional

import requests
import pytesseract
from pdf2image import convert_from_path
from PIL import Image

from config import Config
from services.tika_client import TikaClient

logger = logging.getLogger(__name__)


class DocumentProcessor:
    """
    Service charg√© d'analyser les documents (images/PDF) :

    - Si VISION_ENABLE = true et format support√© : envoi √† un mod√®le Vision (LM Studio).
    - Sinon (ou en cas d'√©chec) : fallback OCR Tesseract classique.

    Le r√©sultat est un texte brut pr√™t √† √™tre index√© via RAG Proxy.
    """

    def __init__(self, config: Config) -> None:
        self.config = config

        # Chargement du prompt Vision depuis un fichier (si pr√©sent)
        self.vision_prompt: str = (
            config.load_prompt(config.vision_prompt_file) or self._get_default_prompt()
        )
        if not config.load_prompt(config.vision_prompt_file):
            logger.warning("Using hardcoded Vision AI prompt as fallback")
        
        # Initialisation du client Tika (si activ√©)
        self.tika_client: Optional[TikaClient] = None
        if config.tika_enable:
            self.tika_client = TikaClient(
                server_url=config.tika_server_url,
                timeout=config.tika_timeout,
            )
            logger.info("TikaClient initialis√© (TIKA_ENABLE=true)")
        else:
            logger.info("TikaClient d√©sactiv√© (TIKA_ENABLE=false)")

    # ------------------------------------------------------------------ #
    # API publique
    # ------------------------------------------------------------------ #
    def analyze_document(self, file_path: str | Path) -> Optional[str]:
        """
        Analyse un document et renvoie un texte descriptif/ocris√©.

        Pipeline d'extraction adaptatif :
        
        IMAGES (JPG/PNG) :
        1. Vision AI (si activ√©) - description visuelle riche
        2. Tika OCR (fallback)
        3. Tesseract OCR (fallback final)
        
        DOCUMENTS (PDF, DOCX, etc.) :
        1. Tika (extraction native optimale)
        2. Vision AI (si activ√© et Tika √©choue)
        3. Tesseract OCR (fallback final)

        - Retourne une cha√Æne non vide si analyse r√©ussie.
        - Retourne None si tout a √©chou√© ou si le r√©sultat est vide.
        """
        path = Path(file_path)
        ext = path.suffix.lower()
        logger.debug("Analyse document : %s (ext=%s)", path.name, ext)

        # D√©terminer le type de fichier
        is_image = ext in {".jpg", ".jpeg", ".png"}
        is_pdf = ext == ".pdf"
        
        # V√©rifier si Vision AI est activ√© pour ce type
        vision_enabled = False
        if is_image and self.config.vision_enable_images:
            vision_enabled = True
        elif is_pdf and self.config.vision_enable_pdf:
            vision_enabled = True

        # ========== PIPELINE POUR LES IMAGES ==========
        if is_image:
            vision_result = None
            tika_metadata = None
            
            # 1. Vision AI pour description visuelle riche
            if vision_enabled:
                try:
                    vision_result = self._analyze_with_vision_llm(path)
                    if not vision_result:
                        logger.debug("Vision AI n'a pas retourn√© de r√©sultat pour %s", path.name)
                except Exception as e:
                    logger.warning(
                        "‚ö†Ô∏è √âchec Vision IA sur %s (%s).",
                        path.name,
                        e,
                    )
            
            # 2. Tika pour m√©tadonn√©es EXIF (toujours essayer pour les images)
            if self.tika_client:
                try:
                    tika_metadata = self.tika_client.extract_metadata(path)
                    if not tika_metadata:
                        logger.debug("Tika n'a pas retourn√© de m√©tadonn√©es pour %s", path.name)
                except Exception as e:
                    logger.debug("√âchec extraction m√©tadonn√©es Tika pour %s: %s", path.name, e)
            
            # 3. Combiner les r√©sultats Vision AI + EXIF
            if vision_result or tika_metadata:
                return self._combine_vision_and_exif(vision_result, tika_metadata, path)
            
            # 4. Fallback Tika OCR si aucun r√©sultat
            if self.tika_client:
                try:
                    result = self._analyze_with_tika(path)
                    if result:
                        return result
                except Exception as e:
                    logger.warning(
                        "‚ö†Ô∏è √âchec Tika OCR sur %s (%s). Passage √† Tesseract.",
                        path.name,
                        e,
                    )
            
            # 5. Fallback final Tesseract OCR
            return self._analyze_with_tesseract(path)

        # ========== PIPELINE POUR LES DOCUMENTS (PDF, DOCX, etc.) ==========
        else:
            # 1. Priorit√© Tika pour extraction optimale
            if self.tika_client:
                try:
                    result = self._analyze_with_tika(path)
                    if result:
                        return result
                    logger.debug("Tika n'a pas retourn√© de r√©sultat pour %s", path.name)
                except Exception as e:
                    logger.warning(
                        "‚ö†Ô∏è √âchec Tika sur %s (%s). Passage au fallback.",
                        path.name,
                        e,
                    )

            # 2. Fallback Vision AI (si activ√© et autoris√©)
            if vision_enabled and self.config.tika_fallback_to_vision:
                try:
                    result = self._analyze_with_vision_llm(path)
                    if result:
                        return result
                except Exception as e:
                    logger.warning(
                        "‚ö†Ô∏è √âchec Vision IA sur %s (%s). Bascule vers OCR classique.",
                        path.name,
                        e,
                    )

            # 3. Fallback final OCR Tesseract
            return self._analyze_with_tesseract(path)

    # ------------------------------------------------------------------ #
    # OCR Tesseract
    # ------------------------------------------------------------------ #
    def _analyze_with_tesseract(self, path: Path) -> Optional[str]:
        """
        Fallback d'analyse via Tesseract.

        - Pour les PDF : OCR des premi√®res pages seulement (MAX_OCR_PAGES).
        - Pour les images : OCR direct.
        """
        logger.debug("D√©but OCR Tesseract sur %s...", path.name)
        text_content = ""

        try:
            if path.suffix.lower() == ".pdf":
                max_pages = self.config.max_ocr_pages
                dpi = self.config.ocr_dpi

                images = convert_from_path(
                    str(path),
                    dpi=dpi,
                    first_page=1,
                    last_page=max_pages,
                )
                logger.debug(
                    "PDF converti en %d image(s) pour OCR "
                    "(limite %d pages, dpi=%d).",
                    len(images),
                    max_pages,
                    dpi,
                )

                for i, img in enumerate(images, start=1):
                    page_text = pytesseract.image_to_string(
                        img,
                        lang="fra+eng",
                    )
                    text_content += f"\n--- Page {i} (OCR) ---\n{page_text}"

                # Note si on est potentiellement tronqu√©
                if len(images) == max_pages:
                    note = (
                        f"[NOTE] OCR r√©alis√© sur les {max_pages} premi√®res pages du PDF "
                        f"(le document peut √©ventuellement en contenir davantage).\n\n"
                    )
                    text_content = note + text_content

            else:
                img = Image.open(path)
                text_content = pytesseract.image_to_string(
                    img,
                    lang="fra+eng",
                )

            text_content = text_content.strip()
            if text_content:
                logger.debug("OCR Tesseract termin√© avec succ√®s sur %s.", path.name)
                return text_content

            logger.debug(
                "OCR Tesseract termin√© sur %s mais r√©sultat vide.",
                path.name,
            )
            return None

        except Exception as e:
            logger.error("‚ùå Erreur Tesseract sur %s : %s", path.name, e, exc_info=True)
            return None

    # ------------------------------------------------------------------ #
    # Apache Tika
    # ------------------------------------------------------------------ #
    def _analyze_with_tika(self, path: Path) -> Optional[str]:
        """
        Analyse via Apache Tika pour extraction de texte universelle.

        - Extrait le texte du document
        - R√©cup√®re les m√©tadonn√©es pertinentes (auteur, date, titre)
        - Retourne le texte format√© avec m√©tadonn√©es ou None si √©chec
        """
        if not self.tika_client:
            return None

        logger.info("üìÑ Extraction Tika pour %s...", path.name)

        # Extraction du texte
        text = self.tika_client.extract_text(path)
        if not text:
            return None

        # Extraction des m√©tadonn√©es (optionnel, enrichit le contenu)
        metadata = self.tika_client.extract_metadata(path)

        # Construction du r√©sultat avec m√©tadonn√©es pertinentes
        result_parts = ["--- EXTRACTION TIKA ---\n"]

        # Ajout des m√©tadonn√©es int√©ressantes si disponibles
        if metadata:
            if "dc:title" in metadata:
                result_parts.append(f"Titre: {metadata['dc:title']}\n")
            if "dc:creator" in metadata or "Author" in metadata:
                author = metadata.get("dc:creator") or metadata.get("Author")
                result_parts.append(f"Auteur: {author}\n")
            if "dcterms:created" in metadata or "Creation-Date" in metadata:
                created = metadata.get("dcterms:created") or metadata.get("Creation-Date")
                result_parts.append(f"Date de cr√©ation: {created}\n")
            if "dcterms:modified" in metadata or "Last-Modified" in metadata:
                modified = metadata.get("dcterms:modified") or metadata.get("Last-Modified")
                result_parts.append(f"Derni√®re modification: {modified}\n")
            if "Content-Type" in metadata:
                result_parts.append(f"Type: {metadata['Content-Type']}\n")

            if len(result_parts) > 1:  # Si on a des m√©tadonn√©es
                result_parts.append("\n")

        result_parts.append(text)

        return "".join(result_parts)

    def _combine_vision_and_exif(
        self,
        vision_result: Optional[str],
        metadata: Optional[Dict[str, Any]],
        path: Path,
    ) -> str:
        """
        Combine la description Vision AI avec les m√©tadonn√©es EXIF pour les images.
        
        Args:
            vision_result: R√©sultat de l'analyse Vision AI
            metadata: M√©tadonn√©es extraites par Tika
            path: Chemin du fichier image
            
        Returns:
            Texte combin√© avec description visuelle + EXIF
        """
        parts = []
        
        # Ajouter la description Vision AI
        if vision_result:
            parts.append(vision_result)
        
        # Ajouter les m√©tadonn√©es EXIF pertinentes
        if metadata:
            exif_parts = []
            
            # Date de prise de vue
            date_keys = ["EXIF:DateTimeOriginal", "Date/Time Original", "Creation-Date", "dcterms:created"]
            for key in date_keys:
                if key in metadata:
                    exif_parts.append(f"üìÖ Date de prise de vue: {metadata[key]}")
                    break
            
            # Localisation GPS
            gps_lat = metadata.get("GPS Latitude")
            gps_lon = metadata.get("GPS Longitude")
            if gps_lat and gps_lon:
                exif_parts.append(f"üìç Coordonn√©es GPS: {gps_lat}, {gps_lon}")
            
            # Appareil photo
            make = metadata.get("EXIF:Make") or metadata.get("Make")
            model = metadata.get("EXIF:Model") or metadata.get("Model")
            if make or model:
                camera = f"{make} {model}".strip() if make and model else (make or model)
                exif_parts.append(f"üì∏ Appareil: {camera}")
            
            # Param√®tres de prise de vue
            iso = metadata.get("EXIF:ISOSpeedRatings") or metadata.get("ISO Speed Ratings")
            aperture = metadata.get("EXIF:FNumber") or metadata.get("F-Number")
            exposure = metadata.get("EXIF:ExposureTime") or metadata.get("Exposure Time")
            focal = metadata.get("EXIF:FocalLength") or metadata.get("Focal Length")
            
            settings = []
            if iso:
                settings.append(f"ISO {iso}")
            if aperture:
                settings.append(f"f/{aperture}")
            if exposure:
                settings.append(f"{exposure}s")
            if focal:
                settings.append(f"{focal}mm")
            
            if settings:
                exif_parts.append(f"‚öôÔ∏è Param√®tres: {', '.join(settings)}")
            
            # R√©solution
            width = metadata.get("Image Width") or metadata.get("tiff:ImageWidth")
            height = metadata.get("Image Height") or metadata.get("tiff:ImageLength")
            if width and height:
                exif_parts.append(f"üìè R√©solution: {width}√ó{height} pixels")
            
            # Ajouter les m√©tadonn√©es EXIF au r√©sultat
            if exif_parts:
                parts.append("\n\n--- M√âTADONN√âES EXIF ---")
                parts.append("\n" + "\n".join(exif_parts))
        
        # Si aucun r√©sultat, retourner une note
        if not parts:
            return f"Image analys√©e ({path.name}) - Aucune information extraite."
        
        return "".join(parts)

    # ------------------------------------------------------------------ #
    # Vision LLM (LM Studio)
    # ------------------------------------------------------------------ #
    def _analyze_with_vision_llm(self, path: Path) -> Optional[str]:
        """
        Analyse via un mod√®le Vision (LM Studio compatible OpenAI).

        - Pour les PDF, on convertit la premi√®re page en image (PNG).
        - On envoie une requ√™te /chat/completions avec image en base64.
        """
        logger.info("üëÅÔ∏è Envoi de %s √† LM Studio (Vision)...", path.name)

        temp_img_path = path
        is_temp = False

        # Si PDF, convertit la premi√®re page en image temporaire
        if path.suffix.lower() == ".pdf":
            dpi = self.config.ocr_dpi
            pages = convert_from_path(
                str(path),
                first_page=1,
                last_page=1,
                dpi=dpi,
            )
            if not pages:
                raise RuntimeError("PDF sans page exploitable")

            temp_img_path = path.with_suffix(".tmp.png")
            pages[0].save(temp_img_path, "PNG")
            is_temp = True

        try:
            image_bytes = temp_img_path.read_bytes()
            base64_image = base64.b64encode(image_bytes).decode("utf-8")
        finally:
            if is_temp and temp_img_path.exists():
                temp_img_path.unlink()

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.config.ai_api_key}",
        }

        payload = {
            "model": self.config.ai_model_name,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": self.vision_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{base64_image}"
                            },
                        },
                    ],
                }
            ],
            "temperature": self.config.vision_temperature,
            "max_tokens": self.config.vision_max_tokens,
        }

        try:
            response = requests.post(
                self.config.ai_api_url,
                headers=headers,
                json=payload,
                timeout=self.config.vision_timeout,
            )
            response.raise_for_status()
            result = response.json()
        except requests.RequestException as e:
            logger.error(
                "‚ùå Erreur HTTP Vision IA sur %s : %s",
                path.name,
                e,
                exc_info=True,
            )
            raise
        except ValueError as e:
            logger.error(
                "‚ùå Erreur de d√©codage JSON Vision IA sur %s : %s",
                path.name,
                e,
                exc_info=True,
            )
            raise

        choices = result.get("choices") or []
        if not choices:
            logger.error(
                "R√©ponse Vision IA sans 'choices' pour %s : %s",
                path.name,
                str(result)[:500],
            )
            return None

        content = (
            choices[0]
            .get("message", {})
            .get("content", "")
            .strip()
        )
        if not content:
            logger.error(
                "R√©ponse Vision IA vide pour %s : %s",
                path.name,
                str(result)[:500],
            )
            return None

        logger.info("‚úÖ R√©ponse Vision IA re√ßue pour %s.", path.name)
        return (
            f"--- ANALYSE VISION IA ({self.config.ai_model_name}) ---\n\n"
            f"{content}"
        )

    # ------------------------------------------------------------------ #
    # Prompt par d√©faut
    # ------------------------------------------------------------------ #
    @staticmethod
    def _get_default_prompt() -> str:
        """Prompt de fallback si aucun fichier de prompt Vision n'est disponible."""
        return (
            "Agis comme un expert en analyse visuelle. Analyse cette image et adapte ta r√©ponse selon son contenu.\n\n"
            "**√âTAPE 1 : Identification**\n"
            "D√©termine d'abord le type de contenu :\n"
            "- DOCUMENT : Facture, re√ßu, lettre, rapport, contrat, graphique, capture d'√©cran avec texte structur√©\n"
            "- PHOTO : Paysage, √©v√©nement, portrait, sc√®ne de vie, objet, architecture\n\n"
            "**√âTAPE 2 : Analyse Adaptative**\n\n"
            "# Analyse de l'Image\n\n"
            "## 1. Classification\n"
            "- **Type** : (DOCUMENT ou PHOTO)\n"
            "- **Cat√©gorie Pr√©cise** : (ex: Facture, Paysage urbain, Portrait de groupe, etc.)\n\n"
            "## 2. M√©ta-donn√©es\n"
            "**Pour un DOCUMENT :**\n"
            "- **Date** : (Format YYYY-MM-DD si visible, sinon 'Non sp√©cifi√©e')\n"
            "- **√âmetteur** : (Entreprise/Personne)\n"
            "- **Destinataire** : (Entreprise/Personne)\n"
            "- **Sujet/Titre** : (Objet principal)\n"
            "- **Donn√©es Financi√®res** : (Montant HT, TVA, TTC, Devise si applicable, sinon 'N/A')\n\n"
            "**Pour une PHOTO :**\n"
            "- **Lieu** : (Localisation visible ou estim√©e, ou 'Non identifi√©')\n"
            "- **Date/P√©riode** : (Si visible sur l'image ou d√©ductible du contexte)\n"
            "- **Sujets Principaux** : (Personnes, objets, √©l√©ments dominants)\n"
            "- **Ambiance/Style** : (Couleurs dominantes, atmosph√®re, style photographique)\n\n"
            "## 3. Description D√©taill√©e\n"
            "**Pour un DOCUMENT :** Un r√©sum√© concis du contenu et de l'objectif (2-3 phrases).\n\n"
            "**Pour une PHOTO :** Une description riche de la sc√®ne incluant :\n"
            "   - Ce qui est visible au premier plan / arri√®re-plan\n"
            "   - Les couleurs, la lumi√®re, l'ambiance\n"
            "   - Les actions ou √©v√©nements captur√©s\n"
            "   - Tout d√©tail pertinent ou remarquable\n\n"
            "## 4. Transcription Textuelle\n"
            "**Transcris TOUT texte visible** (panneaux, enseignes, l√©gendes, texte structur√©) en respectant la mise en forme.\n"
            "Si aucun texte n'est pr√©sent, √©cris : 'Aucun texte visible.'"
        )
